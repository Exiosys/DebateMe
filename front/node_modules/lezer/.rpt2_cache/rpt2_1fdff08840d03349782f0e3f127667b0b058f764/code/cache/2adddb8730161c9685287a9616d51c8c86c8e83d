{"code":"/// Tokenizers write the tokens they read into instances of this class.\nvar Token = /** @class */ (function () {\n    function Token() {\n        /// The start of the token. This is set by the parser, and should not\n        /// be mutated by the tokenizer.\n        this.start = -1;\n        /// This starts at -1, and should be updated to a term id when a\n        /// matching token is found.\n        this.value = -1;\n        /// When setting `.value`, you should also set `.end` to the end\n        /// position of the token. (You'll usually want to use the `accept`\n        /// method.)\n        this.end = -1;\n    }\n    /// Accept a token, setting `value` and `end` to the given values.\n    Token.prototype.accept = function (value, end) {\n        this.value = value;\n        this.end = end;\n    };\n    /// @internal\n    Token.prototype.asError = function (start, eof) {\n        this.start = start;\n        if (start == eof) {\n            this.value = 0 /* Eof */;\n            this.end = start;\n        }\n        else {\n            this.value = 3 /* Err */;\n            this.end = start + 1;\n        }\n        return this;\n    };\n    return Token;\n}());\nexport { Token };\n/// An `InputStream` that is backed by a single, flat string.\nvar StringStream = /** @class */ (function () {\n    function StringStream(string, length) {\n        if (length === void 0) { length = string.length; }\n        this.string = string;\n        this.length = length;\n    }\n    StringStream.prototype.get = function (pos) {\n        return pos < 0 || pos >= this.length ? -1 : this.string.charCodeAt(pos);\n    };\n    StringStream.prototype.read = function (from, to) { return this.string.slice(from, Math.min(this.length, to)); };\n    StringStream.prototype.clip = function (at) { return new StringStream(this.string, at); };\n    return StringStream;\n}());\nexport { StringStream };\n/// @internal\nvar TokenGroup = /** @class */ (function () {\n    function TokenGroup(data, id) {\n        this.data = data;\n        this.id = id;\n    }\n    TokenGroup.prototype.token = function (input, token, stack) { readToken(this.data, input, token, stack, this.id); };\n    return TokenGroup;\n}());\nexport { TokenGroup };\nTokenGroup.prototype.contextual = false;\nvar ExternalTokenizer = /** @class */ (function () {\n    function ExternalTokenizer(token, options) {\n        if (options === void 0) { options = {}; }\n        this.token = token;\n        this.contextual = options && options.contextual || false;\n    }\n    return ExternalTokenizer;\n}());\nexport { ExternalTokenizer };\n// Tokenizer data is stored a big uint16 array containing, for each\n// state:\n//\n//  - A group bitmask, indicating what token groups are reachable from\n//    this state, so that paths that can only lead to tokens not in\n//    any of the current groups can be cut off early.\n//\n//  - The position of the end of the state's sequence of accepting\n//    tokens\n//\n//  - The number of outgoing edges for the state\n//\n//  - The accepting tokens, as (token id, group mask) pairs\n//\n//  - The outgoing edges, as (start character, end character, state\n//    index) triples, with end character being exclusive\n//\n// This function interprets that data, running through a stream as\n// long as new states with the a matching group mask can be reached,\n// and updating `token` when it matches a token.\nfunction readToken(data, input, token, stack, group) {\n    var state = 0, groupMask = 1 << group;\n    scan: for (var pos = token.start;;) {\n        if ((groupMask & data[state]) == 0)\n            break;\n        var accEnd = data[state + 1];\n        // Check whether this state can lead to a token in the current group\n        // Accept tokens in this state, possibly overwriting\n        // lower-precedence / shorter tokens\n        for (var i = state + 3; i < accEnd; i += 2)\n            if ((data[i + 1] & groupMask) > 0) {\n                var term = data[i];\n                if (token.value == -1 || token.value == term || stack.cx.parser.overrides(term, token.value)) {\n                    token.accept(term, pos);\n                    break;\n                }\n            }\n        var next = input.get(pos++);\n        // Do a binary search on the state's edges\n        for (var low = 0, high = data[state + 2]; low < high;) {\n            var mid = (low + high) >> 1;\n            var index = accEnd + mid + (mid << 1);\n            var from = data[index], to = data[index + 1];\n            if (next < from)\n                high = mid;\n            else if (next >= to)\n                low = mid + 1;\n            else {\n                state = data[index + 2];\n                continue scan;\n            }\n        }\n        break;\n    }\n}\n//# sourceMappingURL=token.js.map","map":"{\"version\":3,\"file\":\"token.js\",\"sourceRoot\":\"\",\"sources\":[\"../../src/token.ts\"],\"names\":[],\"mappings\":\"AAGA,uEAAuE;AACvE;IAAA;QACE,qEAAqE;QACrE,gCAAgC;QAChC,UAAK,GAAG,CAAC,CAAC,CAAA;QACV,gEAAgE;QAChE,4BAA4B;QAC5B,UAAK,GAAG,CAAC,CAAC,CAAA;QACV,gEAAgE;QAChE,mEAAmE;QACnE,YAAY;QACZ,QAAG,GAAG,CAAC,CAAC,CAAA;IAoBV,CAAC;IAlBC,kEAAkE;IAClE,sBAAM,GAAN,UAAO,KAAa,EAAE,GAAW;QAC/B,IAAI,CAAC,KAAK,GAAG,KAAK,CAAA;QAClB,IAAI,CAAC,GAAG,GAAG,GAAG,CAAA;IAChB,CAAC;IAED,aAAa;IACb,uBAAO,GAAP,UAAQ,KAAa,EAAE,GAAW;QAChC,IAAI,CAAC,KAAK,GAAG,KAAK,CAAA;QAClB,IAAI,KAAK,IAAI,GAAG,EAAE;YAChB,IAAI,CAAC,KAAK,cAAW,CAAA;YACrB,IAAI,CAAC,GAAG,GAAG,KAAK,CAAA;SACjB;aAAM;YACL,IAAI,CAAC,KAAK,cAAW,CAAA;YACrB,IAAI,CAAC,GAAG,GAAG,KAAK,GAAG,CAAC,CAAA;SACrB;QACD,OAAO,IAAI,CAAA;IACb,CAAC;IACH,YAAC;AAAD,CAAC,AA9BD,IA8BC;;AAmBD,6DAA6D;AAC7D;IACE,sBAAqB,MAAc,EAAW,MAAsB;QAAtB,uBAAA,EAAA,SAAS,MAAM,CAAC,MAAM;QAA/C,WAAM,GAAN,MAAM,CAAQ;QAAW,WAAM,GAAN,MAAM,CAAgB;IAAG,CAAC;IAExE,0BAAG,GAAH,UAAI,GAAW;QACb,OAAO,GAAG,GAAG,CAAC,IAAI,GAAG,IAAI,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,GAAG,CAAC,CAAA;IACzE,CAAC;IAED,2BAAI,GAAJ,UAAK,IAAY,EAAE,EAAU,IAAY,OAAO,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,IAAI,EAAE,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,CAAC,CAAA,CAAC,CAAC;IAEpG,2BAAI,GAAJ,UAAK,EAAU,IAAI,OAAO,IAAI,YAAY,CAAC,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,CAAA,CAAC,CAAC;IAC/D,mBAAC;AAAD,CAAC,AAVD,IAUC;;AAOD,aAAa;AACb;IAGE,oBAAqB,IAA2B,EAAW,EAAU;QAAhD,SAAI,GAAJ,IAAI,CAAuB;QAAW,OAAE,GAAF,EAAE,CAAQ;IAAG,CAAC;IAEzE,0BAAK,GAAL,UAAM,KAAkB,EAAE,KAAY,EAAE,KAAY,IAAI,SAAS,CAAC,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,EAAE,CAAC,CAAA,CAAC,CAAC;IAC9G,iBAAC;AAAD,CAAC,AAND,IAMC;;AAED,UAAU,CAAC,SAAS,CAAC,UAAU,GAAG,KAAK,CAAA;AAEvC;IAGE,2BAAqB,KAA+D,EACxE,OAAoC;QAApC,wBAAA,EAAA,YAAoC;QAD3B,UAAK,GAAL,KAAK,CAA0D;QAElF,IAAI,CAAC,UAAU,GAAG,OAAO,IAAI,OAAO,CAAC,UAAU,IAAI,KAAK,CAAA;IAC1D,CAAC;IACH,wBAAC;AAAD,CAAC,AAPD,IAOC;;AAED,mEAAmE;AACnE,SAAS;AACT,EAAE;AACF,sEAAsE;AACtE,mEAAmE;AACnE,qDAAqD;AACrD,EAAE;AACF,kEAAkE;AAClE,YAAY;AACZ,EAAE;AACF,gDAAgD;AAChD,EAAE;AACF,2DAA2D;AAC3D,EAAE;AACF,mEAAmE;AACnE,wDAAwD;AACxD,EAAE;AACF,kEAAkE;AAClE,oEAAoE;AACpE,gDAAgD;AAChD,SAAS,SAAS,CAAC,IAA2B,EAC3B,KAAkB,EAClB,KAAY,EACZ,KAAY,EACZ,KAAa;IAC9B,IAAI,KAAK,GAAG,CAAC,EAAE,SAAS,GAAG,CAAC,IAAI,KAAK,CAAA;IACrC,IAAI,EAAE,KAAK,IAAI,GAAG,GAAG,KAAK,CAAC,KAAK,IAAI;QAClC,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC;YAAE,MAAK;QACzC,IAAI,MAAM,GAAG,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,CAAA;QAC5B,oEAAoE;QACpE,oDAAoD;QACpD,oCAAoC;QACpC,KAAK,IAAI,CAAC,GAAG,KAAK,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,EAAE,CAAC,IAAI,CAAC;YAAE,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,SAAS,CAAC,GAAG,CAAC,EAAE;gBAC7E,IAAI,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,CAAA;gBAClB,IAAI,KAAK,CAAC,KAAK,IAAI,CAAC,CAAC,IAAI,KAAK,CAAC,KAAK,IAAI,IAAI,IAAI,KAAK,CAAC,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,IAAI,EAAE,KAAK,CAAC,KAAK,CAAC,EAAE;oBAC5F,KAAK,CAAC,MAAM,CAAC,IAAI,EAAE,GAAG,CAAC,CAAA;oBACvB,MAAK;iBACN;aACF;QACD,IAAI,IAAI,GAAG,KAAK,CAAC,GAAG,CAAC,GAAG,EAAE,CAAC,CAAA;QAC3B,0CAA0C;QAC1C,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,IAAI,GAAG,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,EAAE,GAAG,GAAG,IAAI,GAAG;YACrD,IAAI,GAAG,GAAG,CAAC,GAAG,GAAG,IAAI,CAAC,IAAI,CAAC,CAAA;YAC3B,IAAI,KAAK,GAAG,MAAM,GAAG,GAAG,GAAG,CAAC,GAAG,IAAI,CAAC,CAAC,CAAA;YACrC,IAAI,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,EAAE,EAAE,GAAG,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,CAAA;YAC5C,IAAI,IAAI,GAAG,IAAI;gBAAE,IAAI,GAAG,GAAG,CAAA;iBACtB,IAAI,IAAI,IAAI,EAAE;gBAAE,GAAG,GAAG,GAAG,GAAG,CAAC,CAAA;iBAC7B;gBAAE,KAAK,GAAG,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;gBAAC,SAAS,IAAI,CAAA;aAAE;SAChD;QACD,MAAK;KACN;AACH,CAAC\"}","dts":{"name":"/home/marijn/src/lezer/lezer/token.d.ts","writeByteOrderMark":false,"text":"import { Stack } from \"./stack\";\nexport declare class Token {\n    start: number;\n    value: number;\n    end: number;\n    accept(value: number, end: number): void;\n    asError(start: number, eof: number): this;\n}\nexport interface InputStream {\n    length: number;\n    get(pos: number): number;\n    read(from: number, to: number): string;\n    clip(at: number): InputStream;\n}\nexport declare class StringStream implements InputStream {\n    readonly string: string;\n    readonly length: number;\n    constructor(string: string, length?: number);\n    get(pos: number): number;\n    read(from: number, to: number): string;\n    clip(at: number): StringStream;\n}\nexport interface Tokenizer {\n    token(input: InputStream, token: Token, stack: Stack): void;\n    contextual: boolean;\n}\nexport declare class TokenGroup implements Tokenizer {\n    readonly data: Readonly<Uint16Array>;\n    readonly id: number;\n    contextual: boolean;\n    constructor(data: Readonly<Uint16Array>, id: number);\n    token(input: InputStream, token: Token, stack: Stack): void;\n}\nexport declare class ExternalTokenizer {\n    readonly token: (input: InputStream, token: Token, stack: Stack) => void;\n    contextual: boolean;\n    constructor(token: (input: InputStream, token: Token, stack: Stack) => void, options?: {\n        contextual?: boolean;\n    });\n}\n"}}

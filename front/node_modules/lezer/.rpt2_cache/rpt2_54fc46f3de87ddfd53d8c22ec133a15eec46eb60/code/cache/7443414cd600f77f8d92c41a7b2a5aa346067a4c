{"code":"var StringStream = /** @class */ (function () {\n    function StringStream(string, length) {\n        if (length === void 0) { length = string.length; }\n        this.string = string;\n        this.length = length;\n        this.pos = 0;\n        this.token = -1;\n        this.tokenEnd = -1;\n    }\n    StringStream.prototype.next = function () {\n        if (this.pos == this.length)\n            return -1;\n        return this.string.charCodeAt(this.pos++);\n    };\n    StringStream.prototype.peek = function (pos) {\n        if (pos === void 0) { pos = this.pos; }\n        return pos < 0 || pos >= this.length ? -1 : this.string.charCodeAt(pos);\n    };\n    StringStream.prototype.accept = function (term, pos) {\n        if (pos === void 0) { pos = this.pos; }\n        this.token = term;\n        this.tokenEnd = pos;\n    };\n    StringStream.prototype.goto = function (n) {\n        this.pos = this.tokenEnd = n;\n        this.token = -1;\n        return this;\n    };\n    StringStream.prototype.read = function (from, to) { return this.string.slice(from, Math.min(this.length, to)); };\n    StringStream.prototype.clip = function (at) { return new StringStream(this.string, at); };\n    return StringStream;\n}());\nexport { StringStream };\nvar TokenGroup = /** @class */ (function () {\n    function TokenGroup(data, id) {\n        this.data = data;\n        this.id = id;\n    }\n    TokenGroup.prototype.token = function (input, stack) { token(this.data, input, stack, this.id); };\n    return TokenGroup;\n}());\nexport { TokenGroup };\nTokenGroup.prototype.contextual = false;\nvar ExternalTokenizer = /** @class */ (function () {\n    function ExternalTokenizer(token, options) {\n        if (options === void 0) { options = {}; }\n        this.token = token;\n        this.contextual = options && options.contextual || false;\n    }\n    return ExternalTokenizer;\n}());\nexport { ExternalTokenizer };\n// Tokenizer data is stored a big uint16 array containing, for each\n// state:\n//\n//  - A group bitmask, indicating what token groups are reachable from\n//    this state, so that paths that can only lead to tokens not in\n//    any of the current groups can be cut off early.\n//\n//  - The position of the end of the state's sequence of accepting\n//    tokens\n//\n//  - The number of outgoing edges for the state\n//\n//  - The accepting tokens, as (token id, group mask) pairs\n//\n//  - The outgoing edges, as (start character, end character, state\n//    index) triples, with end character being exclusive\n//\n// This function interprets that data, running through a stream as\n// long as new states with the a matching group mask can be reached,\n// and calling `input.accept` when it matches a token.\nfunction token(data, input, stack, group) {\n    var state = 0, groupMask = 1 << group;\n    scan: for (;;) {\n        if ((groupMask & data[state]) == 0)\n            break;\n        var accEnd = data[state + 1];\n        // Check whether this state can lead to a token in the current group\n        // Accept tokens in this state, possibly overwriting\n        // lower-precedence / shorter tokens\n        for (var i = state + 3; i < accEnd; i += 2)\n            if ((data[i + 1] & groupMask) > 0) {\n                var term = data[i];\n                if (input.token == -1 || input.token == term || stack.cx.parser.overrides(term, input.token)) {\n                    input.accept(term);\n                    break;\n                }\n            }\n        var next = input.next();\n        // Do a binary search on the state's edges\n        for (var low = 0, high = data[state + 2]; low < high;) {\n            var mid = (low + high) >> 1;\n            var index = accEnd + mid + (mid << 1);\n            var from = data[index], to = data[index + 1];\n            if (next < from)\n                high = mid;\n            else if (next >= to)\n                low = mid + 1;\n            else {\n                state = data[index + 2];\n                continue scan;\n            }\n        }\n        break;\n    }\n}\n//# sourceMappingURL=token.js.map","map":"{\"version\":3,\"file\":\"token.js\",\"sourceRoot\":\"\",\"sources\":[\"../../src/token.ts\"],\"names\":[],\"mappings\":\"AAeA;IAKE,sBAAqB,MAAc,EAAW,MAAsB;QAAtB,uBAAA,EAAA,SAAS,MAAM,CAAC,MAAM;QAA/C,WAAM,GAAN,MAAM,CAAQ;QAAW,WAAM,GAAN,MAAM,CAAgB;QAJpE,QAAG,GAAG,CAAC,CAAA;QACP,UAAK,GAAG,CAAC,CAAC,CAAA;QACV,aAAQ,GAAG,CAAC,CAAC,CAAA;IAE0D,CAAC;IAExE,2BAAI,GAAJ;QACE,IAAI,IAAI,CAAC,GAAG,IAAI,IAAI,CAAC,MAAM;YAAE,OAAO,CAAC,CAAC,CAAA;QACtC,OAAO,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,IAAI,CAAC,GAAG,EAAE,CAAC,CAAA;IAC3C,CAAC;IAED,2BAAI,GAAJ,UAAK,GAAc;QAAd,oBAAA,EAAA,MAAM,IAAI,CAAC,GAAG;QACjB,OAAO,GAAG,GAAG,CAAC,IAAI,GAAG,IAAI,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,UAAU,CAAC,GAAG,CAAC,CAAA;IACzE,CAAC;IAED,6BAAM,GAAN,UAAO,IAAY,EAAE,GAAc;QAAd,oBAAA,EAAA,MAAM,IAAI,CAAC,GAAG;QACjC,IAAI,CAAC,KAAK,GAAG,IAAI,CAAA;QACjB,IAAI,CAAC,QAAQ,GAAG,GAAG,CAAA;IACrB,CAAC;IAED,2BAAI,GAAJ,UAAK,CAAS;QACZ,IAAI,CAAC,GAAG,GAAG,IAAI,CAAC,QAAQ,GAAG,CAAC,CAAA;QAC5B,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,CAAA;QACf,OAAO,IAAI,CAAA;IACb,CAAC;IAED,2BAAI,GAAJ,UAAK,IAAY,EAAE,EAAU,IAAY,OAAO,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,IAAI,EAAE,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,CAAC,CAAA,CAAC,CAAC;IAEpG,2BAAI,GAAJ,UAAK,EAAU,IAAI,OAAO,IAAI,YAAY,CAAC,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,CAAA,CAAC,CAAC;IAC/D,mBAAC;AAAD,CAAC,AA9BD,IA8BC;;AAOD;IAGE,oBAAqB,IAA2B,EAAW,EAAU;QAAhD,SAAI,GAAJ,IAAI,CAAuB;QAAW,OAAE,GAAF,EAAE,CAAQ;IAAG,CAAC;IAEzE,0BAAK,GAAL,UAAM,KAAkB,EAAE,KAAY,IAAI,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,EAAE,CAAC,CAAA,CAAC,CAAC;IACrF,iBAAC;AAAD,CAAC,AAND,IAMC;;AAED,UAAU,CAAC,SAAS,CAAC,UAAU,GAAG,KAAK,CAAA;AAEvC;IAGE,2BAAqB,KAAiD,EAC1D,OAAoC;QAApC,wBAAA,EAAA,YAAoC;QAD3B,UAAK,GAAL,KAAK,CAA4C;QAEpE,IAAI,CAAC,UAAU,GAAG,OAAO,IAAI,OAAO,CAAC,UAAU,IAAI,KAAK,CAAA;IAC1D,CAAC;IACH,wBAAC;AAAD,CAAC,AAPD,IAOC;;AAED,mEAAmE;AACnE,SAAS;AACT,EAAE;AACF,sEAAsE;AACtE,mEAAmE;AACnE,qDAAqD;AACrD,EAAE;AACF,kEAAkE;AAClE,YAAY;AACZ,EAAE;AACF,gDAAgD;AAChD,EAAE;AACF,2DAA2D;AAC3D,EAAE;AACF,mEAAmE;AACnE,wDAAwD;AACxD,EAAE;AACF,kEAAkE;AAClE,oEAAoE;AACpE,sDAAsD;AACtD,SAAS,KAAK,CAAC,IAA2B,EAC3B,KAAkB,EAClB,KAAY,EACZ,KAAa;IAC1B,IAAI,KAAK,GAAG,CAAC,EAAE,SAAS,GAAG,CAAC,IAAI,KAAK,CAAA;IACrC,IAAI,EAAE,SAAS;QACb,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC;YAAE,MAAK;QACzC,IAAI,MAAM,GAAG,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,CAAA;QAC5B,oEAAoE;QACpE,oDAAoD;QACpD,oCAAoC;QACpC,KAAK,IAAI,CAAC,GAAG,KAAK,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,EAAE,CAAC,IAAI,CAAC;YAAE,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,SAAS,CAAC,GAAG,CAAC,EAAE;gBAC7E,IAAI,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,CAAA;gBAClB,IAAI,KAAK,CAAC,KAAK,IAAI,CAAC,CAAC,IAAI,KAAK,CAAC,KAAK,IAAI,IAAI,IAAI,KAAK,CAAC,EAAE,CAAC,MAAM,CAAC,SAAS,CAAC,IAAI,EAAE,KAAK,CAAC,KAAK,CAAC,EAAE;oBAC5F,KAAK,CAAC,MAAM,CAAC,IAAI,CAAC,CAAA;oBAClB,MAAK;iBACN;aACF;QACD,IAAI,IAAI,GAAG,KAAK,CAAC,IAAI,EAAE,CAAA;QACvB,0CAA0C;QAC1C,KAAK,IAAI,GAAG,GAAG,CAAC,EAAE,IAAI,GAAG,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,EAAE,GAAG,GAAG,IAAI,GAAG;YACrD,IAAI,GAAG,GAAG,CAAC,GAAG,GAAG,IAAI,CAAC,IAAI,CAAC,CAAA;YAC3B,IAAI,KAAK,GAAG,MAAM,GAAG,GAAG,GAAG,CAAC,GAAG,IAAI,CAAC,CAAC,CAAA;YACrC,IAAI,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,EAAE,EAAE,GAAG,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,CAAA;YAC5C,IAAI,IAAI,GAAG,IAAI;gBAAE,IAAI,GAAG,GAAG,CAAA;iBACtB,IAAI,IAAI,IAAI,EAAE;gBAAE,GAAG,GAAG,GAAG,GAAG,CAAC,CAAA;iBAC7B;gBAAE,KAAK,GAAG,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;gBAAC,SAAS,IAAI,CAAA;aAAE;SAChD;QACD,MAAK;KACN;AACH,CAAC\"}","dts":{"name":"/home/marijn/src/lezer/lezer/token.d.ts","writeByteOrderMark":false,"text":"import { Stack } from \"./stack\";\nexport interface InputStream {\n    pos: number;\n    length: number;\n    next(): number;\n    peek(pos?: number): number;\n    accept(term: number, pos?: number): void;\n    token: number;\n    tokenEnd: number;\n    goto(n: number): InputStream;\n    read(from: number, to: number): string;\n    clip(at: number): InputStream;\n}\nexport declare class StringStream implements InputStream {\n    readonly string: string;\n    readonly length: number;\n    pos: number;\n    token: number;\n    tokenEnd: number;\n    constructor(string: string, length?: number);\n    next(): number;\n    peek(pos?: number): number;\n    accept(term: number, pos?: number): void;\n    goto(n: number): this;\n    read(from: number, to: number): string;\n    clip(at: number): StringStream;\n}\nexport interface Tokenizer {\n    token(input: InputStream, stack: Stack): void;\n    contextual: boolean;\n}\nexport declare class TokenGroup implements Tokenizer {\n    readonly data: Readonly<Uint16Array>;\n    readonly id: number;\n    contextual: boolean;\n    constructor(data: Readonly<Uint16Array>, id: number);\n    token(input: InputStream, stack: Stack): void;\n}\nexport declare class ExternalTokenizer {\n    readonly token: (input: InputStream, stack: Stack) => void;\n    contextual: boolean;\n    constructor(token: (input: InputStream, stack: Stack) => void, options?: {\n        contextual?: boolean;\n    });\n}\n"}}
